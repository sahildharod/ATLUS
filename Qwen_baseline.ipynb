{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "556eae37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.19.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.23.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (16.0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.22.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.12.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.8/dist-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers==4.37.0 in /usr/local/lib/python3.8/dist-packages (4.37.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.8/dist-packages (from transformers==4.37.0) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.37.0) (0.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.37.0) (2022.10.31)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.37.0) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.37.0) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.8/dist-packages (from transformers==4.37.0) (0.23.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.37.0) (22.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.37.0) (1.22.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.37.0) (3.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.37.0) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0) (4.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0) (2023.12.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.37.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.37.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.37.0) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.37.0) (3.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (8.1.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install transformers==4.37.0\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2638151f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76e7d6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "device = \"cuda:0,2\" # the device to load the model onto\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen1.5-0.5B-Chat\",torch_dtype=torch.bfloat16,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-0.5B-Chat\", padding_side = \"left\")\n",
    "\n",
    "# mainmodel = AutoModelForCausalLM.from_pretrained(\n",
    "#     \"Qwen/Qwen1.5-0.5B-Chat\",torch_dtype=torch.bfloat16,\n",
    "# )\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-0.5B-Chat\", padding_side = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ac4f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I fix errors in my grammar when writin...</td>\n",
       "      <td>c033f4b800f390a3e9bb4266d22242c90852a1ef8dee6f...</td>\n",
       "      <td>[{'content': 'How can I fix errors in my gramm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Create a comprehensive guide for writing a pro...</td>\n",
       "      <td>532aec37e5778500677847da77e15ab2d05f40dba9c84d...</td>\n",
       "      <td>[{'content': 'Create a comprehensive guide for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do people in Hinduism practice daily devot...</td>\n",
       "      <td>173bc31d726a5e8b5e3381a159d98d168a5a94e963449b...</td>\n",
       "      <td>[{'content': 'How do people in Hinduism practi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the concept of torsion fields help ex...</td>\n",
       "      <td>74ea19b8ebeeab77180987254f06007fec14ab1d9d8012...</td>\n",
       "      <td>[{'content': 'How does the concept of torsion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Numerical Modeling of Multi-Species Transport ...</td>\n",
       "      <td>fedf09781f1405da3b2dbc0b5f0a572275b58d2c02e200...</td>\n",
       "      <td>[{'content': 'Numerical Modeling of Multi-Spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256027</th>\n",
       "      <td>How does the lymphatic system contribute to im...</td>\n",
       "      <td>829f5887f74c1ccdfad6cdf3d96c615fd2eda96c1681b8...</td>\n",
       "      <td>[{'content': 'How does the lymphatic system co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256028</th>\n",
       "      <td>Most weekends this semester, you’d find me in ...</td>\n",
       "      <td>fdcd85f6bc6c99ec6f0dd7904103f087e45f2638bea865...</td>\n",
       "      <td>[{'content': 'Most weekends this semester, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256029</th>\n",
       "      <td>Who were the top contenders in the 1984 U.S. O...</td>\n",
       "      <td>3e98da789057180b68e0bde2e7825dc1f50d6cf80a8956...</td>\n",
       "      <td>[{'content': 'Who were the top contenders in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256030</th>\n",
       "      <td>Build a C++ program that calculates the sum of...</td>\n",
       "      <td>8d631e52ca4a32022a7f3d5d2395fe4582211788d78271...</td>\n",
       "      <td>[{'content': 'Build a C++ program that calcula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256031</th>\n",
       "      <td>What are the three important components of Chi...</td>\n",
       "      <td>67883804688acbe5e5660d8c4492967c598197f03c8b24...</td>\n",
       "      <td>[{'content': 'What are the three important com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256032 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   prompt  \\\n",
       "0       How can I fix errors in my grammar when writin...   \n",
       "1       Create a comprehensive guide for writing a pro...   \n",
       "2       How do people in Hinduism practice daily devot...   \n",
       "3       How does the concept of torsion fields help ex...   \n",
       "4       Numerical Modeling of Multi-Species Transport ...   \n",
       "...                                                   ...   \n",
       "256027  How does the lymphatic system contribute to im...   \n",
       "256028  Most weekends this semester, you’d find me in ...   \n",
       "256029  Who were the top contenders in the 1984 U.S. O...   \n",
       "256030  Build a C++ program that calculates the sum of...   \n",
       "256031  What are the three important components of Chi...   \n",
       "\n",
       "                                                prompt_id  \\\n",
       "0       c033f4b800f390a3e9bb4266d22242c90852a1ef8dee6f...   \n",
       "1       532aec37e5778500677847da77e15ab2d05f40dba9c84d...   \n",
       "2       173bc31d726a5e8b5e3381a159d98d168a5a94e963449b...   \n",
       "3       74ea19b8ebeeab77180987254f06007fec14ab1d9d8012...   \n",
       "4       fedf09781f1405da3b2dbc0b5f0a572275b58d2c02e200...   \n",
       "...                                                   ...   \n",
       "256027  829f5887f74c1ccdfad6cdf3d96c615fd2eda96c1681b8...   \n",
       "256028  fdcd85f6bc6c99ec6f0dd7904103f087e45f2638bea865...   \n",
       "256029  3e98da789057180b68e0bde2e7825dc1f50d6cf80a8956...   \n",
       "256030  8d631e52ca4a32022a7f3d5d2395fe4582211788d78271...   \n",
       "256031  67883804688acbe5e5660d8c4492967c598197f03c8b24...   \n",
       "\n",
       "                                                 messages  \n",
       "0       [{'content': 'How can I fix errors in my gramm...  \n",
       "1       [{'content': 'Create a comprehensive guide for...  \n",
       "2       [{'content': 'How do people in Hinduism practi...  \n",
       "3       [{'content': 'How does the concept of torsion ...  \n",
       "4       [{'content': 'Numerical Modeling of Multi-Spec...  \n",
       "...                                                   ...  \n",
       "256027  [{'content': 'How does the lymphatic system co...  \n",
       "256028  [{'content': 'Most weekends this semester, you...  \n",
       "256029  [{'content': 'Who were the top contenders in t...  \n",
       "256030  [{'content': 'Build a C++ program that calcula...  \n",
       "256031  [{'content': 'What are the three important com...  \n",
       "\n",
       "[256032 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Loading the dataset\n",
    "dataset = load_dataset(\"HuggingFaceH4/ultrachat_200k\")\n",
    "df = dataset['train_gen'].to_pandas()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d496eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please create a Python program that can arrang...</td>\n",
       "      <td>f342d434df9d62c2c650c1ae3fc4131c63cf5aba90f3c8...</td>\n",
       "      <td>[{'content': 'Please create a Python program t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Develop a visually appealing and informative p...</td>\n",
       "      <td>32e81af0cec9cdd373d111d9a31ab20b7b34c6e0a1431b...</td>\n",
       "      <td>[{'content': 'Develop a visually appealing and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Provide a list of creative and unique ideas fo...</td>\n",
       "      <td>b06774fb7da80ae9e3e3334111b1a75dbe6dae985ecff8...</td>\n",
       "      <td>[{'content': 'Provide a list of creative and u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Write a comprehensive list of practical and fe...</td>\n",
       "      <td>5e5ba66dc543521db297358a8c2ab3170027d391eba870...</td>\n",
       "      <td>[{'content': 'Write a comprehensive list of pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Write a short story centered around a mystery ...</td>\n",
       "      <td>85be9fe2b602c32c2b4b8e4b094c57f0d28650b9a62525...</td>\n",
       "      <td>[{'content': 'Write a short story centered aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>Here is a piece of text: A new diabetes vaccin...</td>\n",
       "      <td>c72ad1c88d4f5f0360c7a97b847aece0af3b8ddb5e25d3...</td>\n",
       "      <td>[{'content': 'Here is a piece of text: A new d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>Sorry it’s been so long since we’ve gotten tog...</td>\n",
       "      <td>4c16c4e377ac9355af999922965bbcbc7b12d18f0ca4b1...</td>\n",
       "      <td>[{'content': 'Sorry it’s been so long since we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Compare and contrast the use of symbolism in S...</td>\n",
       "      <td>81f583efb78216709a5e4209df8ae91073349770b67ddf...</td>\n",
       "      <td>[{'content': 'Compare and contrast the use of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>Create a 5-paragraph persuasive essay in MLA f...</td>\n",
       "      <td>854d90a3190f7ffdc9153fcd5d010b3915ae4daec47dfe...</td>\n",
       "      <td>[{'content': 'Create a 5-paragraph persuasive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>Create a product demo to share with potential ...</td>\n",
       "      <td>13c14c8e80e1c4870feb2b1b29afc76f6525b44ba983c5...</td>\n",
       "      <td>[{'content': 'Create a product demo to share w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt  \\\n",
       "0     Please create a Python program that can arrang...   \n",
       "1     Develop a visually appealing and informative p...   \n",
       "2     Provide a list of creative and unique ideas fo...   \n",
       "3     Write a comprehensive list of practical and fe...   \n",
       "4     Write a short story centered around a mystery ...   \n",
       "...                                                 ...   \n",
       "1495  Here is a piece of text: A new diabetes vaccin...   \n",
       "1496  Sorry it’s been so long since we’ve gotten tog...   \n",
       "1497  Compare and contrast the use of symbolism in S...   \n",
       "1498  Create a 5-paragraph persuasive essay in MLA f...   \n",
       "1499  Create a product demo to share with potential ...   \n",
       "\n",
       "                                              prompt_id  \\\n",
       "0     f342d434df9d62c2c650c1ae3fc4131c63cf5aba90f3c8...   \n",
       "1     32e81af0cec9cdd373d111d9a31ab20b7b34c6e0a1431b...   \n",
       "2     b06774fb7da80ae9e3e3334111b1a75dbe6dae985ecff8...   \n",
       "3     5e5ba66dc543521db297358a8c2ab3170027d391eba870...   \n",
       "4     85be9fe2b602c32c2b4b8e4b094c57f0d28650b9a62525...   \n",
       "...                                                 ...   \n",
       "1495  c72ad1c88d4f5f0360c7a97b847aece0af3b8ddb5e25d3...   \n",
       "1496  4c16c4e377ac9355af999922965bbcbc7b12d18f0ca4b1...   \n",
       "1497  81f583efb78216709a5e4209df8ae91073349770b67ddf...   \n",
       "1498  854d90a3190f7ffdc9153fcd5d010b3915ae4daec47dfe...   \n",
       "1499  13c14c8e80e1c4870feb2b1b29afc76f6525b44ba983c5...   \n",
       "\n",
       "                                               messages  \n",
       "0     [{'content': 'Please create a Python program t...  \n",
       "1     [{'content': 'Develop a visually appealing and...  \n",
       "2     [{'content': 'Provide a list of creative and u...  \n",
       "3     [{'content': 'Write a comprehensive list of pr...  \n",
       "4     [{'content': 'Write a short story centered aro...  \n",
       "...                                                 ...  \n",
       "1495  [{'content': 'Here is a piece of text: A new d...  \n",
       "1496  [{'content': 'Sorry it’s been so long since we...  \n",
       "1497  [{'content': 'Compare and contrast the use of ...  \n",
       "1498  [{'content': 'Create a 5-paragraph persuasive ...  \n",
       "1499  [{'content': 'Create a product demo to share w...  \n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Random Sampling\n",
    "subset_size = 1500  \n",
    "\n",
    "# Use the sample() method to select a random subset\n",
    "df = df.sample(n=subset_size)\n",
    "df.reset_index(inplace = True)\n",
    "df = df[['prompt','prompt_id','messages']]\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d81ace8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>- 1 red bell pepper, sliced</td>\n",
       "      <td>- 1 yellow bell pepper, sliced\\n- 1 orange bel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>- Clear and concise language</td>\n",
       "      <td>- Avoidance of overly technical or jargon-heav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>5. Quality of support provided</td>\n",
       "      <td>I am not capable of providing support in the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>10. Add salt and pepper to taste.</td>\n",
       "      <td>I do not have the ability to taste or add salt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>How can I make a dairy-free curry?</td>\n",
       "      <td>There are several ways to make a dairy-free cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Translate the phrase \"composition of paper on ...</td>\n",
       "      <td>La composición de papel sobre varios temas. Nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>Read the passage below and answer the question...</td>\n",
       "      <td>Is there evidence that North Korea has nuclear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>Cerebral somatic oximeter is also known as reg...</td>\n",
       "      <td>Cerebral somatic oximeters, also known as regi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>I was awarded a PhD in bioinformatics from the...</td>\n",
       "      <td>The author, who was awarded a PhD in bioinform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>Read the passage below and answer the question...</td>\n",
       "      <td>The reviewer is critical of Bob Dylan's new al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt  \\\n",
       "1116                        - 1 red bell pepper, sliced   \n",
       "744                        - Clear and concise language   \n",
       "731                      5. Quality of support provided   \n",
       "1008                  10. Add salt and pepper to taste.   \n",
       "1216                 How can I make a dairy-free curry?   \n",
       "...                                                 ...   \n",
       "43    Translate the phrase \"composition of paper on ...   \n",
       "570   Read the passage below and answer the question...   \n",
       "1396  Cerebral somatic oximeter is also known as reg...   \n",
       "617   I was awarded a PhD in bioinformatics from the...   \n",
       "966   Read the passage below and answer the question...   \n",
       "\n",
       "                                                 answer  \n",
       "1116  - 1 yellow bell pepper, sliced\\n- 1 orange bel...  \n",
       "744   - Avoidance of overly technical or jargon-heav...  \n",
       "731   I am not capable of providing support in the t...  \n",
       "1008  I do not have the ability to taste or add salt...  \n",
       "1216  There are several ways to make a dairy-free cu...  \n",
       "...                                                 ...  \n",
       "43    La composición de papel sobre varios temas. Nu...  \n",
       "570   Is there evidence that North Korea has nuclear...  \n",
       "1396  Cerebral somatic oximeters, also known as regi...  \n",
       "617   The author, who was awarded a PhD in bioinform...  \n",
       "966   The reviewer is critical of Bob Dylan's new al...  \n",
       "\n",
       "[1500 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please email a local nail salon and request pe...</td>\n",
       "      <td>Subject: Customized Nail Art Recommendations f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please share a motivational quote that inspire...</td>\n",
       "      <td>\"The secret of getting ahead is getting starte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please provide a list of at least five self-he...</td>\n",
       "      <td>1. \"The Power of Now\" by Eckhart Tolle - This ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Write a 10-line rhyming poem in free verse tha...</td>\n",
       "      <td>Amidst the crowd, I stand alone,\\nLost in a se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Write a step-by-step recipe for a hearty veget...</td>\n",
       "      <td>Hearty Vegetable Soup Recipe\\n\\nIngredients:\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>Translate the phrase \"composition of paper on ...</td>\n",
       "      <td>La composición de papel sobre varios temas. Nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>Read the passage below and answer the question...</td>\n",
       "      <td>Is there evidence that North Korea has nuclear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>Cerebral somatic oximeter is also known as reg...</td>\n",
       "      <td>Cerebral somatic oximeters, also known as regi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>I was awarded a PhD in bioinformatics from the...</td>\n",
       "      <td>The author, who was awarded a PhD in bioinform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>Read the passage below and answer the question...</td>\n",
       "      <td>The reviewer is critical of Bob Dylan's new al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1024 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt  \\\n",
       "0     Please email a local nail salon and request pe...   \n",
       "1     Please share a motivational quote that inspire...   \n",
       "2     Please provide a list of at least five self-he...   \n",
       "3     Write a 10-line rhyming poem in free verse tha...   \n",
       "4     Write a step-by-step recipe for a hearty veget...   \n",
       "...                                                 ...   \n",
       "1019  Translate the phrase \"composition of paper on ...   \n",
       "1020  Read the passage below and answer the question...   \n",
       "1021  Cerebral somatic oximeter is also known as reg...   \n",
       "1022  I was awarded a PhD in bioinformatics from the...   \n",
       "1023  Read the passage below and answer the question...   \n",
       "\n",
       "                                                 answer  \n",
       "0     Subject: Customized Nail Art Recommendations f...  \n",
       "1     \"The secret of getting ahead is getting starte...  \n",
       "2     1. \"The Power of Now\" by Eckhart Tolle - This ...  \n",
       "3     Amidst the crowd, I stand alone,\\nLost in a se...  \n",
       "4     Hearty Vegetable Soup Recipe\\n\\nIngredients:\\n...  \n",
       "...                                                 ...  \n",
       "1019  La composición de papel sobre varios temas. Nu...  \n",
       "1020  Is there evidence that North Korea has nuclear...  \n",
       "1021  Cerebral somatic oximeters, also known as regi...  \n",
       "1022  The author, who was awarded a PhD in bioinform...  \n",
       "1023  The reviewer is critical of Bob Dylan's new al...  \n",
       "\n",
       "[1024 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "## 1) Separating prompts and responses\n",
    "# Concatenate all 'content' entries in the arrays\n",
    "# contents = df['messages'].apply(lambda x: x[1]['content'])\n",
    "answers = []\n",
    "for i in range(len(df)):\n",
    "#     print(i)\n",
    "    if(len(df.at[i,'messages'])<2):\n",
    "        df.drop(i,inplace=True)\n",
    "        \n",
    "for i in range(len(df)):\n",
    "    content = df.iat[i,2][1]['content']\n",
    "    answers.append(content)\n",
    "# Create a new column in the DataFrame with the concatenated content\n",
    "df['answer'] = answers\n",
    "\n",
    "df = df[['prompt','answer']]\n",
    "\n",
    "## 2) Sorting according to prompt length to incorporate curriculum learning\n",
    "df['length_col'] = df['prompt'].apply(len)\n",
    "\n",
    "# Sort the DataFrame by the length column\n",
    "df_sorted = df.sort_values(by='length_col', ascending=True)  # Use ascending=False for descending order\n",
    "df = df_sorted[['prompt','answer']]\n",
    "display(df)\n",
    "\n",
    "## 3) Removing garbage prompts with very small lengths and hence insufficient context\n",
    "df=df[476:]\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('index',axis=1)\n",
    "df = df[['prompt','answer']]\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7a138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the dataloader class\n",
    "class Customdataset(Dataset):\n",
    "    def __init__(self,original_dataset):\n",
    "        self.original_dataset = original_dataset\n",
    "    def __len__(self):\n",
    "        return len(self.original_dataset)\n",
    "    def __getitem__(self,index):\n",
    "        prompt = self.original_dataset.iat[index,0]\n",
    "        response = self.original_dataset.iat[index,1]\n",
    "        return prompt,response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dcdd649",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing the dataloader\n",
    "batch_size = 64\n",
    "d_train = Customdataset(df)\n",
    "dataloader = DataLoader(d_train, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3140c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "580722ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the custom tokenizer\n",
    "def tokenize_and_pad(texts, tokenizer):\n",
    "    # Tokenize the batch of texts\n",
    "    #tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenized_batches = [tokenizer(batch, return_tensors=\"pt\", padding=False, truncation=True, max_length = 1024) for batch in texts]\n",
    "    max_length = max(len(text['input_ids'][0]) for text in tokenized_batches)\n",
    "    tokenized_batches = [tokenizer(batch, return_tensors=\"pt\", padding=False, truncation=True, max_length = max_length) for batch in texts]\n",
    "\n",
    "    # Pad the sequences with zeros at the end\n",
    "    for batch in tokenized_batches:\n",
    "        for key in batch.keys():\n",
    "    # Calculate the amount of padding needed\n",
    "            padding_length = max(0, max_length - len(batch[key][0]))\n",
    "            if key==\"attention_mask\":\n",
    "                pad_value = 0\n",
    "            else:    \n",
    "                pad_value = tokenizer.convert_tokens_to_ids('<|endoftext|>')  # Assuming you have a tokenizer object\n",
    "\n",
    "    # Perform left padding with the <s> token\n",
    "            if padding_length > 0:\n",
    "                padding_tensor = torch.full((batch[key].shape[0], padding_length), pad_value)\n",
    "\n",
    "                # Concatenate along the correct dimension\n",
    "                # If you want to add padding to the right (columns), use dim=1\n",
    "                batch[key] = torch.cat([ padding_tensor,batch[key]], dim=1)\n",
    "                \n",
    "        \n",
    "    return tokenized_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5df99dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using BLEU Score as the evaluation metric\n",
    "def calculate_bleu_score(paragraph1, paragraph2):\n",
    "    # Remove tokens in the form of <...> from both paragraphs\n",
    "    paragraph1_clean = \" \".join(word for word in paragraph1.split() if not word.startswith(\"<\") and not word.endswith(\">\"))\n",
    "    paragraph2_clean = \" \".join(word for word in paragraph2.split() if not word.startswith(\"<\") and not word.endswith(\">\"))\n",
    "    \n",
    "    # Tokenize the paragraphs into lists of words\n",
    "    reference = nltk.word_tokenize(paragraph1_clean)\n",
    "    candidate = nltk.word_tokenize(paragraph2_clean)\n",
    "    \n",
    "    # Calculate BLEU scores\n",
    "    bleu_1 = sentence_bleu([reference], candidate, weights=(1, 0, 0, 0),smoothing_function=nltk.translate.bleu_score.SmoothingFunction().method4)\n",
    "    bleu_2 = sentence_bleu([reference], candidate, weights=(0.5, 0.5, 0, 0),smoothing_function=nltk.translate.bleu_score.SmoothingFunction().method4)\n",
    "    bleu_3 = sentence_bleu([reference], candidate, weights=(0.33, 0.33, 0.33, 0),smoothing_function=nltk.translate.bleu_score.SmoothingFunction().method4)\n",
    "    bleu_4 = sentence_bleu([reference], candidate,smoothing_function=nltk.translate.bleu_score.SmoothingFunction().method4)\n",
    "    \n",
    "    return bleu_1, bleu_2, bleu_3, bleu_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f83302c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 1024)\n",
      "    (layers): ModuleList(\n",
      "      (0): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (1): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (2): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (3): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (4): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (5): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (6): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (7): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (8): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (9): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (10): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (11): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (12): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (13): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (14): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (15): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (16): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (17): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (18): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (19): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (20): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (21): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (22): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "      (23): Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Initializing the optimizer and loading the model\n",
    "device = \"cuda:0\"\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-6)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84961b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step No 0\n",
      "Step No 1\n",
      "Step No 2\n",
      "Step No 3\n",
      "Step No 4\n",
      "Step No 5\n",
      "Step No 6\n",
      "Step No 7\n",
      "Step No 8\n",
      "Step No 9\n",
      "Step No 10\n",
      "Step No 11\n",
      "Step No 12\n",
      "Step No 13\n",
      "Step No 14\n",
      "Step No 15\n",
      "Average BLEU1 Score is 0.11013402805278596\n"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "\n",
    "for step,batch in enumerate(dataloader):\n",
    "    \n",
    "    print(\"Step No \"+str(step))\n",
    "    prompts, ground_truth = batch\n",
    "    messages = [[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}] for prompt in prompts]\n",
    "    text = [tokenizer.apply_chat_template(message, tokenize=False, add_generation_prompt=True) for message in messages]\n",
    "    tokenized_batches = tokenize_and_pad(text,tokenizer)\n",
    "    prompt_ids = torch.stack([x['input_ids'][0].to(device) for x in tokenized_batches], dim = 0)\n",
    "    prompt_attention_mask = torch.stack([x['attention_mask'][0].to(device) for x in tokenized_batches], dim = 0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        synthetic_response = model.generate(input_ids = prompt_ids, max_new_tokens = 2048)\n",
    "        output=[output_ids[len(input_ids):] for input_ids, output_ids in zip(tokenized_batches[0].input_ids, synthetic_response)]\n",
    "        synthetic_response_ids = torch.empty((1,output[0].size(0))).to(device)\n",
    "        for j in range(batch_size):\n",
    "            output=[output_ids[len(input_ids):] for input_ids, output_ids in zip(tokenized_batches[j].input_ids, synthetic_response)]\n",
    "            synthetic_response_ids=torch.cat([synthetic_response_ids.long(),output[0].unsqueeze(0)],dim = 0)\n",
    "        synthetic_response_ids=synthetic_response_ids[1:,:]\n",
    "        \n",
    "        ground_truth_messages = [[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": ground_tru}] for ground_tru in ground_truth]\n",
    "        ground_truth_text = [ tokenizer.apply_chat_template(ground_truth_message,tokenize=False,add_generation_prompt=True) for ground_truth_message in ground_truth_messages]\n",
    "        \n",
    "    for i in range(len(synthetic_response_ids)):\n",
    "        scores = calculate_bleu_score(tokenizer.decode(synthetic_response_ids[i]),ground_truth_text[i])\n",
    "        score_list.append(scores)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    model.to(device)\n",
    "            \n",
    "avg_bleu_score = sum(score[0] for score in score_list)/len(score_list)\n",
    "print(f\"Average BLEU1 Score is {avg_bleu_score}\")\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
